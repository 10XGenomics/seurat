---
title: 'Guided Clustering of the Microwell-seq Mouse Cell Atlas'
output:
  html_document:
    theme: united
  pdf_document: default
date: 'Compiled: `r format(Sys.Date(), "%B %d, %Y")`'
---

```{r markdown.setup, include=FALSE}
all_times <- list()  # store the time for each chunk
knitr::knit_hooks$set(time_it = local({
  now <- NULL
  function(before, options) {
    if (before) {
      now <<- Sys.time()
    } else {
      res <- difftime(Sys.time(), now, units = "secs")
      all_times[[options$label]] <<- res
    }
  }
}))
knitr::opts_chunk$set(
  tidy = TRUE,
  tidy.opts = list(width.cutoff = 120),
  fig.width = 10,
  message = FALSE,
  warning = FALSE,
  time_it = TRUE
)
```

In the following tutorial, we examine the recently published [Microwell-seq “Mouse Cell Atlas”](http://www.cell.com/cell/abstract/S0092-8674(18)30116-8), composed of hundreds of thousands of cells derived from all major mouse organs. For those that are getting started using Seurat, we recommend first working through our [3k PBMC tutorial](http://satijalab.org/seurat/v3.0/pbmc3k_tutorial.html), which introduces the basic functionality of the package.

Our goal is to demonstrate a workflow for handling very large datasets in Seurat, emphasizing recent improvements we have made for speed and memory efficiency. We do not perform downstream biological analyses on the resulting clusters, but encourage users to explore this dataset and interpret this exciting resource. All analyses here are performed in memory, but we also now support storage on-disk (using the HDF5-based [loom framework](http://loompy.org/)). See this [vignette](http://satijalab.org/seurat/mca_loom.html) for a workflow of the same MCA dataset using [loomR](http://satijalab.org/loomR/loomR_tutorial.html).

# Setup the Seurat Object
The original data for the MCA is available [here](https://figshare.com/articles/MCA_DGE_Data/5435866). For ease of getting started, we provide a sparse matrix R data file (.rds) file containing the combined expression matrix and the published metadata file [here](https://www.dropbox.com/s/8d8t4od38oojs6i/MCA.zip?dl=1). 

```{r load.data}
library(Seurat)
library(patchwork)
mca.matrix <- readRDS(file = "../data/MCA_merged_mat.rds")
mca.metadata <- read.csv(file = "../data/MCA_All-batch-removed-assignments.csv", row.names = 1)
```

We will analyze ~242,000 cells that were assigned a cluster ID in the original study. As a result, we don’t do perform additional QC steps or filtration steps here.

```{r setup}
mca <- CreateSeuratObject(counts = mca.matrix, meta.data = mca.metadata, project = "MouseCellAtlas")
# Only keep annotated cells
mca <- subset(mca, cells = names(which(!is.na(mca$ClusterID))))
# Leaves us with 242k cells
mca
```

# Data Preprocessing

We perform standard log-normalization.

```{r normalize}
mca <- NormalizeData(mca, normalization.method = "LogNormalize", scale.factor = 10000)
```

`FindVariableGenes` calculates the variance and mean for each gene in the dataset in the dataset (storing this in `object[[assay]]@meta.features`). We have observed that for large-cell datasets with unique molecular identifiers, selecting highly variable genes (HVG) simply based on variance mean ratio (VMR) is an efficient and robust strategy. Here, we select the top 1,000 HVG for downstream analysis.

```{r var.genes}
mca <- FindVariableFeatures(mca)
```

We calculate and regress out mitochondrial expression per cell. 

<div class="panel panel-success">
  <div class="panel-heading">Suggestions for large datasets </div>
  <div class="panel-body"> <ul><li> ScaleData now has the option for multi-core parallel processing, using the future framework. <li> You can perform gene scaling on only the HVF, dramatically improving speed and memory use. Since dimensional reduction is run only on HVF, this will not affect downstream results.</ul></div>
</div> 

```{r scale}
mca[["percent.mt"]] <- PercentageFeatureSet(mca, pattern = "^mt-")
mca <- ScaleData(mca, vars.to.regress = "percent.mt")
```

# Dimensional Reduction (PCA)

```{r pca, message=TRUE}
mca <- RunPCA(mca, npcs = 100, ndims.print = 1:5, nfeatures.print = 5)
```

<div class="panel panel-success">
  <div class="panel-heading">Suggestions for large datasets </div>
  <div class="panel-body"> <ul><li> To select downstream PCs for analysis, `JackStraw` now also features mutli-core parallelization. However, for data sets of this size, the saturation of explained variance, along with the visualization of PC 'metagenes', are likely to be more effective. We select 75 PCs here for downstream analysis.</ul></div>
</div>

```{r pca.viz1}
ElbowPlot(mca, ndims = 100)
```

```{r pca.viz2, fig.height=12}
DimHeatmap(mca, dims = c(1:3, 70:75), cells = 500, balanced = TRUE)
```

# Graph-based clustering

We now cluster the data in lower-dimensional space. Our approach was heavily inspired by recent manuscripts which applied graph-based clustering approaches to scRNA-seq data [[SNN-Cliq, Xu and Su, Bioinformatics, 2015]](http://bioinformatics.oxfordjournals.org/content/early/2015/02/10/bioinformatics.btv088.abstract) and CyTOF data [[PhenoGraph, Levine *et al*., Cell, 2015]](http://www.ncbi.nlm.nih.gov/pubmed/26095251). 

<div class="panel panel-success">
  <div class="panel-heading">Suggestions for large datasets </div>
  <div class="panel-body"> <ul><li>The construction of the shared nearest neighbor graph is now fully implemented in C++, significantly improving performance. <li>To further increase speed, you can employ an approximate nearest neighbor search via the [RANN package](https://cran.r-project.org/web/packages/RANN/index.html) by increasing the `nn.eps` parameter. Setting this at 0 (the default) represents an exact neighbor search.<li> By default, we perform 100 random starts for clustering and select the result with highest modularity. You can lower this through the `n.start` parameter to reduce clustering time.</ul></div>
</div>


```{r clustering}
mca <- FindNeighbors(mca, reduction = "pca", dims = 1:75, nn.eps = 0.5)
mca <- FindClusters(mca, resolution = 3, n.start = 10)
```

# Visualization (t-SNE/UMAP)

We use the same principal components that were input for clustering, for two-dimensional visualization with t-SNE or UMAP. 

<div class="panel panel-success">
  <div class="panel-heading">Suggestions for large datasets </div>
  <div class="panel-body"> <ul><li>We now support the use of a modified Fast Fourier Transform-accelerated Interpolation-based t-SNE (FIt-SNE, Kluger Lab, preprint [here](https://arxiv.org/abs/1712.09005)). You need to first compile and install the [software](https://github.com/KlugerLab/FIt-SNE). <li>Increasing `max_iter` can sometimes provide better cluster resolution. <li> We also now support the use of UMAP for dimensional reduction (preprint [here](https://arxiv.org/abs/1802.03426)). To run you need to install the `umap-learn` python [package](https://github.com/lmcinnes/umap). <li> Adjusting `min_dist` and/or `n_neighbors` may help with larger datasets <li>For visualization, the `AugmentPlot` function  will convert only the single cells in the t-SNE plot into a PNG file, while the remainder of the image (axes, labels, etc.) remain as vector graphics. We’ve found that this can be very useful when importing into Adobe Illustrator.</ul></div>
</div>


```{r tsne.umap}
mca <- RunTSNE(mca, dims = 1:75, tsne.method = "FIt-SNE", nthreads = 4, max_iter = 2000)
mca <- RunUMAP(mca, dims = 1:75, min.dist = 0.75, umap.method = "umap-learn")
```

```{r tsne.umap.vis}
library(ggplot2)
p1 <- DimPlot(mca, reduction = "tsne", pt.size = 0.1) + ggtitle(label = "FIt-SNE")
p2 <- DimPlot(mca, reduction = "umap", pt.size = 0.1) + ggtitle(label = "UMAP")
p1 <- AugmentPlot(plot = p1)
p2 <- AugmentPlot(plot = p2)
(p1 + p2) & NoLegend()
```

```{r marker.viz}
p3 <- FeaturePlot(mca, features = c("S100a9", "Sftpc"), reduction = "tsne", pt.size = 0.1, combine = FALSE) 
p3 <- lapply(X = p3, FUN = function(x) AugmentPlot(x + DarkTheme() + NoLegend()))
wrap_plots(p3)
```

### Elapsed time for key steps

These tests were performed on a desktop computer running Ubuntu 16.04.5 LTS with an Intel(R) Core(TM) i7-6800K CPU @ 3.40GHz and 96 GB of RAM.

| Function                                                    | Time          | 
| ------------------------------------------------------------|---------------|
| CreateSeuratObject                                          | 14sec         |
| NormalizeData                                               | 12sec         |
| FindVariableGenes                                           | 22sec         |
| ScaleData (no regression)                                   | 13sec         |
| ScaleData (w/regression)                                    | 3min 7sec     |
| ScaleData (w/regression + parallelization)                  | 1min 21sec    |
| RunPCA                                                      | 6min 24sec    |
| FindNeighbors + FindClusters (default)                      | 38min 15sec   |
| FindNeighbors(nn.eps = 0.5) + FindClusters (10 starts)      | 18min	56sec	  |
| RunTSNE (Rtsne)                                             | 36min 58sec   |
| RunTSNE (FIt-SNE)                                           | 9min 49sec    |

```{r save.img, include = FALSE}
plot <- DimPlot(mca, reduction = "tsne", pt.size = 0.1) + NoLegend() +
  xlab("FIt-SNE1") + ylab("FIT-SNE2") + 
  theme(axis.title = element_text(size = 18), legend.text = element_text(size = 18))
ggsave(filename = "../output/images/mca_tsne.png", height = 7, width = 12, plot = plot)
```

```{r save.times, include = FALSE}
write.csv(x = t(as.data.frame(all_times)), file = "../output/timings/mca_times.csv")
```
